{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import torch as t\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from utils.config import opt\n",
    "from model import FasterRCNNVGG16\n",
    "from trainer import FasterRCNNTrainer\n",
    "from data.util import  read_image\n",
    "from utils.vis_tool import vis_bbox\n",
    "from utils import array_tool as at\n",
    "from PIL import Image, ImageDraw\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn = FasterRCNNVGG16()\n",
    "trainer = FasterRCNNTrainer(faster_rcnn).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    # Unpack the coordinates from the bounding boxes\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "\n",
    "    # Calculate the area of intersection\n",
    "    inter_width = max(0, inter_x_max - inter_x_min)\n",
    "    inter_height = max(0, inter_y_max - inter_y_min)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    # Calculate the area of both bounding boxes\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    # Calculate the area of the union\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Calculate the Intersection over Union (IoU)\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Load the weights\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "# Initialize an empty list to hold the query info data\n",
    "lst_data = []\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/prw/query_info.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into individual elements\n",
    "        elements = line.strip().split()\n",
    "        \n",
    "        # Convert numeric elements to appropriate data types\n",
    "        elements[0] = int(elements[0])  # Convert the first element to int\n",
    "        elements[1:5] = [int(float(x)) for x in elements[1:5]]  # Convert the next four elements to int\n",
    "        #xmin, ymin, width, height = elements[1], elements[2], elements[3], elements[4]\n",
    "        #y2, x2 = ymin + height, xmin + width\n",
    "        \n",
    "        # Append the list of elements to the data list\n",
    "        lst_data.append(elements)\n",
    "\n",
    "# Ensure that the output folder exists\n",
    "output_folder = './query_prw_tog_p_fgsm_distractors_iou'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# List all .jpg files in the input directory\n",
    "input_folder = './frames_tog_p_fgsm'\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
    "\n",
    "not_detected_images = []  # List to store names of images with no detections\n",
    "\n",
    "# Load the distractor image (make sure this is a valid path to your distractor image)\n",
    "distractor_input_folder = './datasets/prw/query_box'\n",
    "distractor_image_path = './assets/example_2.png'\n",
    "distractor_image = Image.open(distractor_image_path)\n",
    "\n",
    "iou_not_found = 0\n",
    "\n",
    "for image_file in image_files:\n",
    "    input_img_path = os.path.join(input_folder, image_file)\n",
    "    output_img_path = os.path.join(output_folder, image_file)\n",
    "        \n",
    "    # Load the image for detection\n",
    "    img = read_image(input_img_path)\n",
    "    img = t.from_numpy(img)[None]\n",
    "    \n",
    "    # Load the image for bounding boxes\n",
    "    img_bboxes = cv2.imread(input_img_path)\n",
    "    \n",
    "    # Perform detection\n",
    "    try:\n",
    "        _bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)       \n",
    "    \n",
    "        # Convert predictions to numpy\n",
    "        bboxes = at.tonumpy(_bboxes[0])\n",
    "        labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "        scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "            \n",
    "        # Filter predictions to show only \"person\" class\n",
    "        person_class_id = 14\n",
    "        person_indices = labels == person_class_id\n",
    "        person_bboxes = bboxes[person_indices]\n",
    "        person_labels = labels[person_indices]\n",
    "        person_scores = scores[person_indices]\n",
    "    \n",
    "        #xmin, ymin, width, height = lst_data[0][1], lst_data[0][2], lst_data[0][3], lst_data[0][4]\n",
    "        #y2, x2 = ymin + height, xmin + width\n",
    "        #cropped_image_annotation = img_bboxes[ymin:y2, xmin:x2]\n",
    "        #cropped_image_annotation_coordinates = [ymin, xmin, y2, x2]\n",
    "        #cv2.imwrite(output_img_path + '_' + str(i) + '_annotation_' + '.jpg', cropped_image_annotation)\n",
    "    \n",
    "        for annotation in lst_data:\n",
    "            if annotation[5] in str(input_img_path):\n",
    "                xmin, ymin, width, height = annotation[1], annotation[2], annotation[3], annotation[4]\n",
    "                y2, x2 = ymin + height, xmin + width\n",
    "                cropped_image_annotation = img_bboxes[ymin:y2, xmin:x2]\n",
    "                cropped_image_annotation_coordinates = [ymin, xmin, y2, x2]\n",
    "                distractor_img = Image.open(distractor_input_folder + '/' + str(annotation[0]) + '_' + input_img_path.split('/')[-1])\n",
    "\n",
    "                if len(bboxes) == 0:\n",
    "                    resized_distractor = distractor_image.resize(distractor_img.size, Image.Resampling.LANCZOS)\n",
    "                    resized_distractor.save(output_folder + '/' + str(annotation[0]) + '_' + annotation[5] + '_00'  + '.jpg', format='JPEG')\n",
    "                    not_detected_images.append(str(annotation[0]) + '_' + image_file[:-4] + '_00' + '.jpg')\n",
    "                for bbox in bboxes:\n",
    "                    xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "                    cropped_image_detector = [xmin, ymin, xmax, ymax]\n",
    "                    cropped_image_detector = img_bboxes[xmin:xmax, ymin:ymax]\n",
    "                    cropped_image_detector_coordinates = [xmin, ymin, xmax, ymax]\n",
    "            \n",
    "                    # Calculate IoU\n",
    "                    iou = calculate_iou(cropped_image_annotation_coordinates, cropped_image_detector_coordinates)\n",
    "                    \n",
    "                    # Check if IoU is greater than or equal to 0.5\n",
    "                    if iou >= 0.5:\n",
    "                        cv2.imwrite(output_folder + '/' + str(annotation[0]) + '_' + annotation[5] + '_00' + '.jpg', cropped_image_detector)\n",
    "                        break\n",
    "                    else:\n",
    "                        iou_not_found = iou_not_found + 1\n",
    "                        if iou_not_found == len(bboxes):\n",
    "                            resized_distractor = distractor_image.resize(distractor_img.size, Image.Resampling.LANCZOS)\n",
    "                            resized_distractor.save(output_folder + '/' + str(annotation[0]) + '_' + annotation[5] + '_00' + '.jpg', format='JPEG')\n",
    "                            not_detected_images.append(str(annotation[0]) + '_' + image_file[:-4] + '_00' + '.jpg')\n",
    "                        pass\n",
    "                iou_not_found = 0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Write the list of not detected images to a file\n",
    "with open('query_not_detected.txt', 'w') as file:\n",
    "    for image_name in not_detected_images:\n",
    "        file.write(image_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "folder_path = './query_prw_iou'\n",
    "not_detected_file = './query_prw_iou_not_detected.txt'\n",
    "\n",
    "# Read the file names from the txt file\n",
    "with open(not_detected_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Clean the file names (strip any surrounding whitespace or newline characters)\n",
    "file_names_to_delete = {line.strip() for line in lines}\n",
    "\n",
    "# List all files in the distractor folder\n",
    "files_in_folder = os.listdir(folder_path)\n",
    "\n",
    "# Delete files that match the exact names in the txt file\n",
    "for file_name in files_in_folder:\n",
    "    if file_name in file_names_to_delete:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the folders\n",
    "query_folder = './query_prw_iou'\n",
    "bounding_box_folder = './bounding_box_test_prw_iou'\n",
    "\n",
    "# Get a set of the identity prefixes from the query folder\n",
    "query_prefixes = {file_name[:3] for file_name in os.listdir(query_folder)}\n",
    "\n",
    "# List all files in the bounding box folder\n",
    "files_in_bounding_box = os.listdir(bounding_box_folder)\n",
    "\n",
    "# Loop through each file in the bounding box folder\n",
    "for file_name in files_in_bounding_box:\n",
    "    # Extract the first three characters (identity prefix) from the file name\n",
    "    file_prefix = file_name[:3]\n",
    "    \n",
    "    # Check if the prefix is not in the query folder's prefixes\n",
    "    if file_prefix not in query_prefixes:\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(bounding_box_folder, file_name)\n",
    "        \n",
    "        # Delete the file\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "# Ensure that the output folder exists\n",
    "output_folder = './query_prw_distractor_no_iou'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# List all .jpg files in the input directory\n",
    "input_folder = './query_prw_no_iou'\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
    "\n",
    "detected_images = []  # List to store names of images with detections\n",
    "\n",
    "# Load the distractor image (make sure this is a valid path to your distractor image)\n",
    "distractor_image_path = './assets/example_2.png'\n",
    "distractor_image = Image.open(distractor_image_path)\n",
    "\n",
    "for image_file in image_files:\n",
    "    input_img_path = os.path.join(input_folder, image_file)\n",
    "    output_img_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "    # Load the image\n",
    "    img = read_image(input_img_path)\n",
    "    img = t.from_numpy(img)[None]\n",
    "\n",
    "    # Load the image for distractor\n",
    "    distractor_img = Image.open(input_img_path)\n",
    "\n",
    "    # Perform detection\n",
    "    try:\n",
    "        _bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)       \n",
    "\n",
    "        # Convert predictions to numpy\n",
    "        bboxes = at.tonumpy(_bboxes[0])\n",
    "        labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "        scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "        \n",
    "        # # Filter predictions to show only \"person\" class\n",
    "        person_class_id = 14\n",
    "        person_indices = labels == person_class_id\n",
    "        person_bboxes = bboxes[person_indices]\n",
    "        person_labels = labels[person_indices]\n",
    "        person_scores = scores[person_indices]\n",
    "        \n",
    "        # Check if there are any detections; if not, create and save a resized distractor image\n",
    "        if len(person_bboxes) == 0:\n",
    "            # Resize the distractor image to match the size of the input image\n",
    "            resized_distractor = distractor_image.resize(distractor_img.size, Image.Resampling.LANCZOS)\n",
    "            # Save the resized distractor image as a JPG\n",
    "            resized_distractor.save(output_img_path, format='JPEG')\n",
    "        else:\n",
    "            # Save the original image if detections were found\n",
    "            detected_images.append(image_file)\n",
    "            normalized_tensor = (img - img.min()) / (img.max() - img.min())\n",
    "            torchvision.utils.save_image(normalized_tensor, output_img_path, format='JPEG')\n",
    "    except:\n",
    "        # Save the distractor image as a JPG\n",
    "        distractor_img.save(output_img_path, format='JPEG')\n",
    "        \n",
    "# Write the list of detected images to a file\n",
    "with open('detected_query_iou_distractor.txt', 'w') as file:\n",
    "    for image_name in detected_images:\n",
    "        file.write(image_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "_bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "# vis_bbox(at.tonumpy(img[0]),\n",
    "#          at.tonumpy(_bboxes[0]),\n",
    "#          at.tonumpy(_labels[0]).reshape(-1),\n",
    "#          at.tonumpy(_scores[0]).reshape(-1))\n",
    "# it failed to find the dog, but if you set threshold from 0.7 to 0.6, you'll find it\n",
    "\n",
    "# Debug: Print all detected labels and their scores\n",
    "# print(\"Detected labels and scores:\")\n",
    "# for label, score in zip(labels, scores):\n",
    "#     print(f\"Label: {label}, Score: {score}\")\n",
    "\n",
    "# Convert predictions to numpy\n",
    "bboxes = at.tonumpy(_bboxes[0])\n",
    "labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "\n",
    "# # Filter predictions to show only \"person\" class\n",
    "person_class_id = 14\n",
    "person_indices = labels == person_class_id\n",
    "person_bboxes = bboxes[person_indices]\n",
    "person_labels = labels[person_indices]\n",
    "person_scores = scores[person_indices]\n",
    "\n",
    "# # Visualize only \"person\" class predictions\n",
    "vis_bbox(at.tonumpy(img[0]),\n",
    "         person_bboxes,\n",
    "         person_labels,\n",
    "         person_scores)\n",
    "\n",
    "# Save the image\n",
    "#save_path = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/cropped_imgs/orl_without_bboxes.jpg'  # Replace with your desired path\n",
    "#normalized_tensor = (img - img.min()) / (img.max() - img.min())\n",
    "#torchvision.utils.save_image(normalized_tensor, save_path, format='jpeg')\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('misc/s15538.jpg')\n",
    "\n",
    "# Define the \"person\" bounding boxes\n",
    "bounding_boxes = person_bboxes\n",
    "\n",
    "# Convert bounding box coordinates to integers\n",
    "bounding_boxes = [[int(coord) for coord in box] for box in bounding_boxes]\n",
    "\n",
    "# Draw the bounding boxes on the image\n",
    "for i, box in enumerate(bounding_boxes):\n",
    "    x1, y1, x2, y2 = box\n",
    "    #cv2.rectangle(image, (y1, x1), (y2, x2), (0, 255, 0), 2)  # (0, 255, 0) is the color (green), 2 is the thickness\n",
    "\n",
    "    # Crop the images within the bounding boxes\n",
    "    cropped_image = image[x1:x2, y1:y2]\n",
    "    \n",
    "    # Save the cropped images\n",
    "    cv2.imwrite(f'/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/cropped_imgs/cropped_image_{i}.jpg', cropped_image)\n",
    "\n",
    "    print(\"{}: {}, {}, {}, {}\".format(i, y1, x1, y2, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_train = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/Train.mat')\n",
    "\n",
    "data_train = mat_train['Train']\n",
    "\n",
    "lst_persons = []\n",
    "lst_image = []\n",
    "lst_images = []\n",
    "lst_coordinates = []\n",
    "\n",
    "for sample in data_train: \n",
    "    #print(sample[0][0][0][0]) # Persons\n",
    "    id_person = int(str(sample[0][0][0][0]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', ''))\n",
    "    lst_persons.append(id_person)\n",
    "    for sample_2 in sample[0][0][0][2][0]:\n",
    "        #print(sample_2[0]) # Images of person\n",
    "        name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "        lst_image.append(name_image)\n",
    "        #print(sample_2[1]) # Coordinates\n",
    "        number_coordinates = str(sample_2[1]).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "        number_coordinates = number_coordinates.split(\" \")\n",
    "        lst_coordinates.append(number_coordinates)\n",
    "    lst_images.append(lst_image)\n",
    "    lst_image = []\n",
    "\n",
    "#print(lst_persons)\n",
    "#print(lst_image)\n",
    "#print(lst_images)\n",
    "#print(lst_coordinates)\n",
    "#total_elements = sum(len(sublist) for sublist in lst_images)\n",
    "#print(total_elements)\n",
    "\n",
    "#i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "z = 1\n",
    "#flag_empty_coordinate = 0\n",
    "counter_number_persons_with_empty_bounding_boxes = 0\n",
    "\n",
    "for sample in lst_persons:\n",
    "    name_person = sample\n",
    "    for sample_2 in lst_images[j]:\n",
    "        image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{sample_2}')\n",
    "        name_image_cleaner = sample_2.replace('s', '')\n",
    "        if lst_coordinates[k][0] != '' and lst_coordinates[k][1] != '' and lst_coordinates[k][2] != '' and lst_coordinates[k][3] != '':\n",
    "            xmin, ymin, width, height = int(lst_coordinates[k][0]), int(lst_coordinates[k][1]), int(lst_coordinates[k][2]), int(lst_coordinates[k][3])\n",
    "            y2, x2 = ymin + height, xmin + width\n",
    "            cropped_image = image[ymin:y2, xmin:x2]\n",
    "            cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_train/{name_person}_c{z}s1_000000_{name_image_cleaner}', cropped_image)\n",
    "            z = z + 1\n",
    "        #else:\n",
    "            #print(name_person, end=',') # Persons with some empty coordinate in an image (not being considered)\n",
    "            #flag_empty_coordinate = 1\n",
    "        k = k + 1\n",
    "    if z == 1:\n",
    "        counter_number_persons_with_empty_bounding_boxes = counter_number_persons_with_empty_bounding_boxes + 1\n",
    "    j = j + 1\n",
    "    z = 1\n",
    "    #if flag_empty_coordinate == 1:\n",
    "        #directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/bounding_box_train/'\n",
    "        #for filename in os.listdir(directory):\n",
    "            #if filename.startswith(str(name_person)):\n",
    "                #file_path = os.path.join(directory, filename)\n",
    "                #os.remove(file_path)\n",
    "        #flag_empty_coordinate = 0\n",
    "    #else:\n",
    "        #i = i + 1\n",
    "    #if i == 751:\n",
    "        #break\n",
    "\n",
    "print(counter_number_persons_with_empty_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_query = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "data_query = mat_query['TestG100']\n",
    "\n",
    "lst_persons = []\n",
    "lst_persons_with_empty_coordinates = []\n",
    "lst_image = []\n",
    "lst_coordinates = []\n",
    "\n",
    "for sample in data_query[0]:\n",
    "     #print(sample[0][0][0][0][3]]) # Persons\n",
    "    id_person = int(str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', ''))\n",
    "    lst_persons.append(id_person)\n",
    "    for sample_2 in sample[0][0]:\n",
    "        #print(sample_2[0]) # Image of persons\n",
    "        name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "        lst_image.append(name_image)\n",
    "        #print(sample_2[1]) # Coordinates\n",
    "        number_coordinates = str(sample_2[1]).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "        number_coordinates = number_coordinates.split(\" \")\n",
    "        lst_coordinates.append(number_coordinates)\n",
    "\n",
    "#print(lst_persons)\n",
    "#print(lst_image)\n",
    "#print(lst_coordinates)\n",
    "\n",
    "# i = 0\n",
    "j = 0\n",
    "# k = 0\n",
    "# z = 1\n",
    "# flag_empty_coordinate = 0\n",
    "counter_number_persons_with_empty_bounding_boxes = 0\n",
    "\n",
    "for sample in lst_persons:\n",
    "    name_person = sample\n",
    "    name_image = lst_image[j]\n",
    "    image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{name_image}')\n",
    "    name_image_cleaner = name_image.replace('s', '')\n",
    "    if lst_coordinates[j][0] != '' and lst_coordinates[j][1] != '' and lst_coordinates[j][2] != '' and lst_coordinates[j][3] != '':\n",
    "        xmin, ymin, width, height = int(lst_coordinates[j][0]), int(lst_coordinates[j][1]), int(lst_coordinates[j][2]), int(lst_coordinates[j][3])\n",
    "        y2, x2 = ymin + height, xmin + width\n",
    "        cropped_image = image[ymin:y2, xmin:x2]\n",
    "        cv2.imwrite(f'datasets/cuhk_sysu/query/{name_person}_c1s1_000000_{name_image_cleaner}', cropped_image)\n",
    "    #z = z + 1\n",
    "    #else:\n",
    "        #print(name_person, end=',') # Persons with some empty coordinate in an image (not being considered)\n",
    "        #flag_empty_coordinate = 1\n",
    "    #k = k + 1\n",
    "    #if z == 1:\n",
    "    else:\n",
    "        lst_persons_with_empty_coordinates.append(name_person)\n",
    "        counter_number_persons_with_empty_bounding_boxes = counter_number_persons_with_empty_bounding_boxes + 1\n",
    "    j = j + 1\n",
    "    #z = 1\n",
    "    #if flag_empty_coordinate == 1:\n",
    "        #directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query/'\n",
    "        #for filename in os.listdir(directory):\n",
    "            #if filename.startswith(str(name_person)):\n",
    "                #file_path = os.path.join(directory, filename)\n",
    "                #os.remove(file_path)\n",
    "        #flag_empty_coordinate = 0\n",
    "    #else:\n",
    "        #i = i + 1\n",
    "    #if i == 750:\n",
    "        #break\n",
    "\n",
    "lst_persons_test = [item for item in lst_persons if item not in lst_persons_with_empty_coordinates]\n",
    "\n",
    "print(counter_number_persons_with_empty_bounding_boxes)\n",
    "print(len(lst_persons_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "data_test = mat_test['TestG100']\n",
    "\n",
    "lst_persons_with_empty_coordinates = []\n",
    "dict_person_images = {}\n",
    "dict_image_coordinates = {}\n",
    "dict_person_images_coordinates = {}\n",
    "\n",
    "for sample in data_test[0]:\n",
    "    id_person = str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    dict_person_images[id_person] = []\n",
    "    dict_person_images_coordinates[id_person] = []\n",
    "    for sample_2 in sample[1][0]:\n",
    "        sample_coordinate = sample_2[1]\n",
    "        if sample_coordinate.size != 0:\n",
    "            name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "            dict_image_coordinates[name_image] = []\n",
    "            dict_person_images[id_person].append(name_image)\n",
    "            number_coordinates = str(sample_coordinate).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "            number_coordinates = number_coordinates.split(\" \")\n",
    "            dict_image_coordinates[name_image].append(number_coordinates)\n",
    "            dict_person_images_coordinates[id_person].append(name_image)\n",
    "            dict_person_images_coordinates[id_person].append(number_coordinates)\n",
    "\n",
    "#print(dict_person_images)\n",
    "#print(dict_image_coordinates)\n",
    "#print(dict_person_images_coordinates)\n",
    "#total_elements = sum(len(sublist) for sublist in lst_images)\n",
    "#print(total_elements)\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "#k = 0\n",
    "z = 2\n",
    "#flag_empty_coordinate = 0\n",
    "counter_number_persons_with_empty_bounding_boxes = 0\n",
    "\n",
    "for sample in lst_persons_test:\n",
    "    name_person = sample\n",
    "    for key, value in dict_person_images_coordinates.items():\n",
    "        if int(key) == name_person:\n",
    "            j = len(value)\n",
    "            while j != 0:\n",
    "                name_image = value[i]\n",
    "                image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{name_image}')\n",
    "                name_image_cleaner = name_image.replace('s', '')\n",
    "                if value[i+1][0] != '' and value[i+1][1] != '' and value[i+1][2] != '' and value[i+1][3] != '':\n",
    "                    xmin, ymin, width, height = int(value[i+1][0]), int(value[i+1][1]), int(value[i+1][2]), int(value[i+1][3])\n",
    "                    y2, x2 = ymin + height, xmin + width\n",
    "                    cropped_image = image[ymin:y2, xmin:x2]\n",
    "                    cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{name_person}_c{z}s1_000000_{name_image_cleaner}', cropped_image)\n",
    "                    z = z + 1\n",
    "                i = i + 2\n",
    "                j = j - 2\n",
    "            if z == 2:\n",
    "                counter_number_persons_with_empty_bounding_boxes = counter_number_persons_with_empty_bounding_boxes + 1\n",
    "                lst_persons_with_empty_coordinates.append(name_person)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    z = 2\n",
    "\n",
    "directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query/'\n",
    "for sample_2 in lst_persons_with_empty_coordinates:\n",
    "    name_person = sample_2\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(str(name_person) + '_'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)\n",
    "\n",
    "lst_persons_final = [item for item in lst_persons_test if item not in lst_persons_with_empty_coordinates]\n",
    "\n",
    "print(counter_number_persons_with_empty_bounding_boxes)\n",
    "print(len(lst_persons_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pool MAT file\n",
    "pool_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/pool.mat')\n",
    "\n",
    "pool_data = pool_mat['pool']\n",
    "\n",
    "lst_pool_imgs = []\n",
    "\n",
    "for sample in pool_data:\n",
    "    sample_img = sample[0]\n",
    "    img_name = str(sample_img).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_pool_imgs.append(img_name)\n",
    "\n",
    "# Load TestG100 MAT file\n",
    "testg100_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "testg100_data = testg100_mat['TestG100']\n",
    "\n",
    "lst_testg100_imgs = []\n",
    "lst_testg100_persons = []\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    sample_img = sample[0][0][0]\n",
    "    sample_person = sample[0][0]\n",
    "    img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_testg100_imgs.append(img_name)\n",
    "    lst_testg100_persons.append(person_identity)\n",
    "    \n",
    "\n",
    "lst_imgs = [item for item in lst_pool_imgs if item not in lst_testg100_imgs]\n",
    "\n",
    "dict_testg100_imgs = {}\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    sample_img = sample[0][0][0]\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    dict_testg100_imgs[person_identity] = []\n",
    "    for sample_2 in sample[1][0]:\n",
    "        sample_coordinate = sample_2[1]\n",
    "        if sample_coordinate.size != 0:\n",
    "            sample_img_2 = sample_2[0]\n",
    "            img_name = str(sample_img_2).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "            dict_testg100_imgs[person_identity].append(img_name)\n",
    "\n",
    "#dict_testg100_imgs = {key: ', '.join(value) for key, value in dict_testg100_imgs.items()}\n",
    "\n",
    "#print(len(lst_imgs))\n",
    "#print(lst_testg100_imgs[0])\n",
    "#print(lst_testg100_persons[0])\n",
    "#print(lst_imgs[0])\n",
    "#print(dict_testg100_imgs)\n",
    "#first_key = next(iter(dict_testg100_imgs))\n",
    "#first_elements = dict_testg100_imgs[first_key]\n",
    "#print(f\"First key: {first_key}\")\n",
    "#print(\"Elements:\", first_elements)\n",
    "\n",
    "#def print_duplicates(input_list):\n",
    "    #i = 0\n",
    "    #seen = set()\n",
    "    #duplicates = set()\n",
    "    #for item in input_list:\n",
    "        #if item in seen:\n",
    "            #duplicates.add(item)\n",
    "        #seen.add(item)\n",
    "    #for duplicate in duplicates:\n",
    "        #print(duplicate)\n",
    "        #i = i + 1\n",
    "    #print(i)\n",
    "\n",
    "# Example usage:\n",
    "#print_duplicates(lst_testg100_imgs)\n",
    "#print(len(lst_imgs) - 167)\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "#print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "#print(\"Header:\", mat['__header__'])\n",
    "#print(\"Version:\", mat['__version__'])\n",
    "#print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'TestG50'\n",
    "#testg100_data = mat['TestG100']\n",
    "#print(\"TestG100 Data:\", testg100_data)\n",
    "\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "#directory = 'datasets/cuhk_sysu/Image/SSM/'\n",
    "#lst_imgs_path = []\n",
    "\n",
    "#for root, dirs, files in os.walk(directory):\n",
    "    #for file in files:\n",
    "        #img_path = os.path.join(root, file)\n",
    "        #lst_imgs_path.append(img_path)\n",
    "\n",
    "#lst_imgs_path = [path.split('SSM/')[1] for path in lst_imgs_path]\n",
    "\n",
    "# Loop through each sample\n",
    "#for sample in testg100_data[0]:  # Assuming testg100g_data[0] to get to the actual data if it's structured with an extra dimension\n",
    "    #sample_img = sample[0][0][0]  # Image\n",
    "for sample in lst_imgs:\n",
    "    #sample_img = sample  # Image\n",
    "    #for sample_2 in sample_img:\n",
    "        #sample_img_2 = sample_2\n",
    "    #sample_img_2 = sample[0][0][0][1]  # Location\n",
    "    #sample_img_3 = sample[1][0][1][1]  # Location\n",
    "    #print(str(sample_img) + str(sample_img_2) + str(sample_img_3))\n",
    "    \n",
    "    #print(str(sample_img))\n",
    "    #print(str(sample_img[3]))\n",
    "    #lst_person.append(str(sample_img[3]))\n",
    "    #i = i + 1\n",
    "\n",
    "    #img_name = str(sample_img[1][0][1][0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    #img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    #if img_name in lst_imgs_path:\n",
    "       #print(len(lst_imgs_path))\n",
    "        \n",
    "        #pass\n",
    "    \n",
    "    #else:\n",
    "\n",
    "        #print(\"b\")\n",
    "\n",
    "    img_name = sample\n",
    "\n",
    "    img_name_cleaner = img_name.replace('s', '')\n",
    "\n",
    "    img = read_image(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "    \n",
    "    image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "    \n",
    "    img = t.from_numpy(img)[None]\n",
    "    \n",
    "    _bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "    \n",
    "    bboxes = at.tonumpy(_bboxes[0])\n",
    "    labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "    scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "        \n",
    "    person_class_id = 14\n",
    "    person_indices = labels == person_class_id\n",
    "    person_bboxes = bboxes[person_indices]\n",
    "    person_labels = labels[person_indices]\n",
    "    person_scores = scores[person_indices]\n",
    "    \n",
    "    bounding_boxes = person_bboxes\n",
    "    \n",
    "    bounding_boxes = [[int(coordinate) for coordinate in box] for box in bounding_boxes]\n",
    "    \n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cropped_image = image[x1:x2, y1:y2]\n",
    "        for key, value in dict_testg100_imgs.items():\n",
    "            if img_name in value:\n",
    "                person_identity = key\n",
    "                cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{person_identity}_c1s1_000000_0{img_name_cleaner}', cropped_image)\n",
    "            #else:\n",
    "                #cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/00000_c1s1_000000_0{img_name_cleaner}', cropped_image)\n",
    "                #break\n",
    "\n",
    "    #print(str(sample_img[1][0][1][0]))\n",
    "    #print(str(sample_img[1][0][1][1]))\n",
    "    #print(str(sample_img[1]))\n",
    "    #print(\"{}, {}\".format(str(sample_img[0]), str(sample_img[1])))\n",
    "\n",
    "#lst_person_cleaned = [s.replace('[', '').replace(']', '').replace(\"'\", '').replace('\"', '') for s in lst_person]\n",
    "\n",
    "#unique_set = set(lst_person_cleaned)\n",
    "\n",
    "# Check for duplicates\n",
    "#if len(unique_set) != len(lst_person_cleaned):\n",
    "    #print(\"There are duplicate elements.\")\n",
    "#else:\n",
    "    #print(\"All elements are unique.\")\n",
    "\n",
    "#print(sorted(lst_person_cleaned))\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pool MAT file\n",
    "pool_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/pool.mat')\n",
    "\n",
    "pool_data = pool_mat['pool']\n",
    "\n",
    "lst_pool_imgs = []\n",
    "\n",
    "for sample in pool_data:\n",
    "    sample_img = sample[0]\n",
    "    img_name = str(sample_img).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_pool_imgs.append(img_name)\n",
    "\n",
    "# Load TestG100 MAT file\n",
    "testg100_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "testg100_data = testg100_mat['TestG100']\n",
    "\n",
    "lst_testg100_imgs = []\n",
    "lst_testg100_persons = []\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    sample_img = sample[0][0][0]\n",
    "    sample_person = sample[0][0]\n",
    "    img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_testg100_imgs.append(img_name)\n",
    "    lst_testg100_persons.append(person_identity)\n",
    "    \n",
    "\n",
    "lst_imgs = [item for item in lst_pool_imgs if item not in lst_testg100_imgs]\n",
    "\n",
    "dict_testg100_imgs = {}\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    sample_img = sample[0][0][0]\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    dict_testg100_imgs[person_identity] = []\n",
    "    for sample_2 in sample[1][0]:\n",
    "        sample_coordinate = sample_2[1]\n",
    "        if sample_coordinate.size != 0:\n",
    "            sample_img_2 = sample_2[0]\n",
    "            img_name = str(sample_img_2).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "            dict_testg100_imgs[person_identity].append(img_name)\n",
    "\n",
    "#dict_testg100_imgs = {key: ', '.join(value) for key, value in dict_testg100_imgs.items()}\n",
    "\n",
    "#print(len(lst_imgs))\n",
    "#print(lst_testg100_imgs[0])\n",
    "#print(lst_testg100_persons[0])\n",
    "#print(lst_imgs[0])\n",
    "#print(dict_testg100_imgs)\n",
    "#first_key = next(iter(dict_testg100_imgs))\n",
    "#first_elements = dict_testg100_imgs[first_key]\n",
    "#print(f\"First key: {first_key}\")\n",
    "#print(\"Elements:\", first_elements)\n",
    "\n",
    "#def print_duplicates(input_list):\n",
    "    #i = 0\n",
    "    #seen = set()\n",
    "    #duplicates = set()\n",
    "    #for item in input_list:\n",
    "        #if item in seen:\n",
    "            #duplicates.add(item)\n",
    "        #seen.add(item)\n",
    "    #for duplicate in duplicates:\n",
    "        #print(duplicate)\n",
    "        #i = i + 1\n",
    "    #print(i)\n",
    "\n",
    "# Example usage:\n",
    "#print_duplicates(lst_testg100_imgs)\n",
    "#print(len(lst_imgs) - 167)\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "#print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "#print(\"Header:\", mat['__header__'])\n",
    "#print(\"Version:\", mat['__version__'])\n",
    "#print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'TestG50'\n",
    "#testg100_data = mat['TestG100']\n",
    "#print(\"TestG100 Data:\", testg100_data)\n",
    "\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "#directory = 'datasets/cuhk_sysu/Image/SSM/'\n",
    "#lst_imgs_path = []\n",
    "\n",
    "#for root, dirs, files in os.walk(directory):\n",
    "    #for file in files:\n",
    "        #img_path = os.path.join(root, file)\n",
    "        #lst_imgs_path.append(img_path)\n",
    "\n",
    "#lst_imgs_path = [path.split('SSM/')[1] for path in lst_imgs_path]\n",
    "\n",
    "# Loop through each sample\n",
    "#for sample in testg100_data[0]:  # Assuming testg100g_data[0] to get to the actual data if it's structured with an extra dimension\n",
    "    #sample_img = sample[0][0][0]  # Image\n",
    "for sample in lst_imgs:\n",
    "    #sample_img = sample  # Image\n",
    "    #for sample_2 in sample_img:\n",
    "        #sample_img_2 = sample_2\n",
    "    #sample_img_2 = sample[0][0][0][1]  # Location\n",
    "    #sample_img_3 = sample[1][0][1][1]  # Location\n",
    "    #print(str(sample_img) + str(sample_img_2) + str(sample_img_3))\n",
    "    \n",
    "    #print(str(sample_img))\n",
    "    #print(str(sample_img[3]))\n",
    "    #lst_person.append(str(sample_img[3]))\n",
    "    #i = i + 1\n",
    "\n",
    "    #img_name = str(sample_img[1][0][1][0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    #img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    #if img_name in lst_imgs_path:\n",
    "       #print(len(lst_imgs_path))\n",
    "        \n",
    "        #pass\n",
    "    \n",
    "    #else:\n",
    "\n",
    "        #print(\"b\")\n",
    "\n",
    "    img_name = sample\n",
    "\n",
    "    img_name_cleaner = img_name.replace('s', '')\n",
    "\n",
    "    img = read_image(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "    \n",
    "    image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "    \n",
    "    img = t.from_numpy(img)[None]\n",
    "    \n",
    "    _bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "    \n",
    "    bboxes = at.tonumpy(_bboxes[0])\n",
    "    labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "    scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "        \n",
    "    person_class_id = 14\n",
    "    person_indices = labels == person_class_id\n",
    "    person_bboxes = bboxes[person_indices]\n",
    "    person_labels = labels[person_indices]\n",
    "    person_scores = scores[person_indices]\n",
    "    \n",
    "    bounding_boxes = person_bboxes\n",
    "    \n",
    "    bounding_boxes = [[int(coordinate) for coordinate in box] for box in bounding_boxes]\n",
    "    \n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cropped_image = image[x1:x2, y1:y2]\n",
    "        for key, value in dict_testg100_imgs.items():\n",
    "            if img_name in value:\n",
    "                person_identity = key\n",
    "                cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{person_identity}_c1s1_000000_0{img_name_cleaner}', cropped_image)\n",
    "            #else:\n",
    "                #cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/00000_c1s1_000000_0{img_name_cleaner}', cropped_image)\n",
    "                #break\n",
    "\n",
    "    #print(str(sample_img[1][0][1][0]))\n",
    "    #print(str(sample_img[1][0][1][1]))\n",
    "    #print(str(sample_img[1]))\n",
    "    #print(\"{}, {}\".format(str(sample_img[0]), str(sample_img[1])))\n",
    "\n",
    "#lst_person_cleaned = [s.replace('[', '').replace(']', '').replace(\"'\", '').replace('\"', '') for s in lst_person]\n",
    "\n",
    "#unique_set = set(lst_person_cleaned)\n",
    "\n",
    "# Check for duplicates\n",
    "#if len(unique_set) != len(lst_person_cleaned):\n",
    "    #print(\"There are duplicate elements.\")\n",
    "#else:\n",
    "    #print(\"All elements are unique.\")\n",
    "\n",
    "#print(sorted(lst_person_cleaned))\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    # Unpack the coordinates from the bounding boxes\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "\n",
    "    # Calculate the area of intersection\n",
    "    inter_width = max(0, inter_x_max - inter_x_min)\n",
    "    inter_height = max(0, inter_y_max - inter_y_min)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    # Calculate the area of both bounding boxes\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    # Calculate the area of the union\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Calculate the Intersection over Union (IoU)\n",
    "    iou = inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "    return iou\n",
    "\n",
    "# Load the weights\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "mat_query = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "data_query = mat_query['TestG100']\n",
    "\n",
    "lst_persons = []\n",
    "lst_persons_with_empty_coordinates = []\n",
    "lst_image = []\n",
    "lst_coordinates = []\n",
    "\n",
    "for sample in data_query[0]:\n",
    "     #print(sample[0][0][0][0][3]]) # Persons\n",
    "    id_person = int(str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', ''))\n",
    "    lst_persons.append(id_person)\n",
    "    for sample_2 in sample[0][0]:\n",
    "        #print(sample_2[0]) # Image of persons\n",
    "        name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "        lst_image.append(name_image)\n",
    "        #print(sample_2[1]) # Coordinates\n",
    "        number_coordinates = str(sample_2[1]).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "        number_coordinates = number_coordinates.split(\" \")\n",
    "        lst_coordinates.append(number_coordinates)\n",
    "\n",
    "# Ensure that the output folder exists\n",
    "output_folder = './query_cuhk_sysu_tog_p_fgsm_distractors_iou'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# List all .jpg files in the input directory\n",
    "input_folder = './SSM_tog_p_fgsm'\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith('.jpg')]\n",
    "\n",
    "not_detected_images = []  # List to store names of images with no detections\n",
    "\n",
    "# Load the distractor image (make sure this is a valid path to your distractor image)\n",
    "distractor_input_folder = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query_cuhk_sysu_no_iou'\n",
    "distractor_image_path = './assets/example_2.png'\n",
    "distractor_image = Image.open(distractor_image_path)\n",
    "\n",
    "j = 0\n",
    "iou_not_found = 0\n",
    "\n",
    "# Open the file for writing\n",
    "with open('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query_info.txt', 'w') as file:\n",
    "    # Iterate through the lists and write each line\n",
    "    for sample in lst_persons:\n",
    "        name_person = sample\n",
    "        name_image = lst_image[j]\n",
    "        image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{name_image}')\n",
    "        name_image_cleaner = name_image.replace('s', '')\n",
    "\n",
    "        if lst_coordinates[j][0] != '' and lst_coordinates[j][1] != '' and lst_coordinates[j][2] != '' and lst_coordinates[j][3] != '':\n",
    "            # Format the line\n",
    "            line = f\"{str(sample)} {str(lst_coordinates[j][0])} {str(lst_coordinates[j][1])} {str(lst_coordinates[j][2])} {str(lst_coordinates[j][3])} {str(name_image)}\\n\"\n",
    "            \n",
    "            # Write the line to the file\n",
    "            file.write(line)\n",
    "\n",
    "        j = j + 1\n",
    "\n",
    "# Initialize an empty list to hold the query info data\n",
    "lst_data = []\n",
    "\n",
    "file.close()\n",
    "\n",
    "# Open the file and read line by line\n",
    "with open('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query_info.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into individual elements\n",
    "        elements = line.strip().split()\n",
    "        \n",
    "        # Convert numeric elements to appropriate data types\n",
    "        elements[0] = int(elements[0])  # Convert the first element to int\n",
    "        elements[1:5] = [int(x) for x in elements[1:5]]  # Convert the next four elements to int\n",
    "        #xmin, ymin, width, height = elements[1], elements[2], elements[3], elements[4]\n",
    "        #y2, x2 = ymin + height, xmin + width\n",
    "        \n",
    "        # Append the list of elements to the data list\n",
    "        lst_data.append(elements)\n",
    "\n",
    "#i = 0\n",
    "\n",
    "for image_file in image_files:\n",
    "    input_img_path = os.path.join(input_folder, image_file)\n",
    "    output_img_path = os.path.join(output_folder, image_file)\n",
    "        \n",
    "    # Load the image for detection\n",
    "    img = read_image(input_img_path)\n",
    "    img = t.from_numpy(img)[None]\n",
    "    \n",
    "    # Load the image for bounding boxes\n",
    "    img_bboxes = cv2.imread(input_img_path)\n",
    "    \n",
    "    # Perform detection\n",
    "    try:\n",
    "        _bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)       \n",
    "    \n",
    "        # Convert predictions to numpy\n",
    "        bboxes = at.tonumpy(_bboxes[0])\n",
    "        labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "        scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "            \n",
    "        # Filter predictions to show only \"person\" class\n",
    "        person_class_id = 14\n",
    "        person_indices = labels == person_class_id\n",
    "        person_bboxes = bboxes[person_indices]\n",
    "        person_labels = labels[person_indices]\n",
    "        person_scores = scores[person_indices]\n",
    "    \n",
    "        for annotation in lst_data:\n",
    "            if annotation[5] in str(input_img_path):\n",
    "                xmin, ymin, width, height = annotation[1], annotation[2], annotation[3], annotation[4]\n",
    "                y2, x2 = ymin + height, xmin + width\n",
    "                cropped_image_annotation = img_bboxes[ymin:y2, xmin:x2]\n",
    "                cropped_image_annotation_coordinates = [ymin, xmin, y2, x2]\n",
    "                try:\n",
    "                    distractor_img = Image.open(distractor_input_folder + '/' + str(annotation[0]) + '_c1s1_000000_' + input_img_path.split('/')[-1].replace('s', ''))\n",
    "                except:\n",
    "                    distractor_img = Image.open(distractor_input_folder + '/' + '8_c1s1_000000_12.jpg')\n",
    "\n",
    "                if len(bboxes) == 0:\n",
    "                    resized_distractor = distractor_image.resize(distractor_img.size, Image.Resampling.LANCZOS)\n",
    "                    resized_distractor.save(output_folder + '/' + str(annotation[0]) + '_c1s1_000000_' + str(annotation[5]).replace('s', ''), format='JPEG')\n",
    "                    not_detected_images.append(str(annotation[0]) + '_c1s1_000000_' + str(annotation[5]).replace('s', ''))\n",
    "                for bbox in bboxes:\n",
    "                    xmin, ymin, xmax, ymax = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "                    cropped_image_detector = [xmin, ymin, xmax, ymax]\n",
    "                    cropped_image_detector = img_bboxes[xmin:xmax, ymin:ymax]\n",
    "                    cropped_image_detector_coordinates = [xmin, ymin, xmax, ymax]\n",
    "            \n",
    "                    # Calculate IoU\n",
    "                    iou = calculate_iou(cropped_image_annotation_coordinates, cropped_image_detector_coordinates)\n",
    "                    \n",
    "                    # Check if IoU is greater than or equal to 0.5\n",
    "                    if iou >= 0.5:\n",
    "                        cv2.imwrite(output_folder + '/' + str(annotation[0]) + '_c1s1_000000_' + str(annotation[5]).replace('s', ''), cropped_image_detector)\n",
    "                        break\n",
    "                    else:\n",
    "                        iou_not_found = iou_not_found + 1\n",
    "                        if iou_not_found == len(bboxes):\n",
    "                            resized_distractor = distractor_image.resize(distractor_img.size, Image.Resampling.LANCZOS)\n",
    "                            resized_distractor.save(output_folder + '/' + str(annotation[0]) + '_c1s1_000000_' + str(annotation[5]).replace('s', ''), format='JPEG')\n",
    "                            not_detected_images.append(str(annotation[0]) + '_c1s1_000000_' + str(annotation[5]).replace('s', ''))\n",
    "                        pass\n",
    "                iou_not_found = 0\n",
    "                #i = i + 1\n",
    "        #if i == 5:\n",
    "            #break\n",
    "        #break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Write the list of not detected images to a file\n",
    "with open('./query_cuhk_sysu_tog_p_fgsm_distractors_iou_not_detected.txt', 'w') as file:\n",
    "    for image_name in not_detected_images:\n",
    "        file.write(image_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the folders\n",
    "query_folder = './query_cuhk_sysu_tog_p_fgsm_distractors_iou'\n",
    "bounding_box_folder = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/bounding_box_test'\n",
    "\n",
    "# Get a set of the identity prefixes from the bounding box folder\n",
    "bounding_box_prefixes = {file_name.split('_')[0] for file_name in os.listdir(bounding_box_folder)}\n",
    "\n",
    "# List all files in the query folder\n",
    "files_in_query = os.listdir(query_folder)\n",
    "\n",
    "# Loop through each file in the query folder\n",
    "for file_name in files_in_query:\n",
    "    # Extract the first three characters (identity prefix) from the file name\n",
    "    file_prefix = file_name.split('_')[0]\n",
    "    \n",
    "    # Check if the prefix is not in the bounding box folder's prefixes\n",
    "    if file_prefix not in bounding_box_prefixes:\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(query_folder, file_name)\n",
    "        \n",
    "        # Delete the file\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "folder_path = './query_cuhk_sysu_p_fgsm_tog_distractors_iou'\n",
    "not_detected_file = './query_cuhk_sysu_p_fgsm_tog_distractors_iou_not_detected.txt'\n",
    "\n",
    "# Read the file names from the txt file\n",
    "with open(not_detected_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Clean the file names (strip any surrounding whitespace or newline characters)\n",
    "file_names_to_delete = {line.strip() for line in lines}\n",
    "\n",
    "# List all files in the distractor folder\n",
    "files_in_folder = os.listdir(folder_path)\n",
    "\n",
    "# Delete files that match the exact names in the txt file\n",
    "for file_name in files_in_folder:\n",
    "    if file_name in file_names_to_delete:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "# Load the image for detection\n",
    "img = read_image('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/s15539.jpg')\n",
    "img = t.from_numpy(img)[None]\n",
    "img_bboxes = cv2.imread('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/s15539.jpg')\n",
    "_bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)       \n",
    "bboxes = at.tonumpy(_bboxes[0])\n",
    "labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "person_class_id = 14\n",
    "person_indices = labels == person_class_id\n",
    "person_bboxes = bboxes[person_indices]\n",
    "person_labels = labels[person_indices]\n",
    "person_scores = scores[person_indices]\n",
    "print(bboxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
