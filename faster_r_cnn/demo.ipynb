{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "import torch as t\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from utils.config import opt\n",
    "from model import FasterRCNNVGG16\n",
    "from trainer import FasterRCNNTrainer\n",
    "from data.util import  read_image\n",
    "from utils.vis_tool import vis_bbox\n",
    "from utils import array_tool as at\n",
    "from PIL import Image, ImageDraw\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image('misc/s15538.jpg')\n",
    "img = t.from_numpy(img)[None]\n",
    "\n",
    "image = cv2.imread('misc/s15538.jpg')\n",
    "\n",
    "# Coordinates for the bounding box\n",
    "y1, x1, y2, x2 = 88, 488, 250, 578  # Example coordinates\n",
    "\n",
    "# Draw a rectangle with red color (BGR: 0, 0, 255) and line thickness of 2\n",
    "cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "#cv2.circle(image, (x2, y2), radius=3, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "cv2.imwrite(f'/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/cropped_imgs/test.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn = FasterRCNNVGG16()\n",
    "trainer = FasterRCNNTrainer(faster_rcnn).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to convert tensor to numpy array\n",
    "def tensor_to_numpy(img_tensor):\n",
    "    img_np = at.tonumpy(img_tensor).transpose((1, 2, 0))  # Convert image to numpy and transpose to (H, W, C)\n",
    "    img_np_2 = (img_np * 255).astype(np.uint8)  # Convert to 8-bit format and ensure values are in 0-255 range\n",
    "    return img_np_2\n",
    "\n",
    "# Save the image to a file\n",
    "def save_image(img_pil, save_path):\n",
    "    imageRGB = cv2.cvtColor(tensor_to_numpy(img_pil[0]), cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(imageRGB)\n",
    "    img.save(save_path)\n",
    "    print(f'Saved image with bounding boxes: {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to download pretrained model from [google drive](https://drive.google.com/open?id=1cQ27LIn-Rig4-Uayzy_gH5-cW-NRGVzY) \n",
    "# 1. model converted from chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in this machine the cupy isn't install correctly... \n",
    "# so it's a little slow\n",
    "trainer.load('/home/cy/chainer_best_model_converted_to_pytorch_0.7053.pth')\n",
    "opt.caffe_pretrain=True # this model was trained from caffe-pretrained model\n",
    "_bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "vis_bbox(at.tonumpy(img[0]),\n",
    "         at.tonumpy(_bboxes[0]),\n",
    "         at.tonumpy(_labels[0]).reshape(-1),\n",
    "         at.tonumpy(_scores[0]).reshape(-1))\n",
    "# it failed to find the dog, but if you set threshold from 0.7 to 0.6, you'll find it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. model trained with torchvision pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "_bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "# vis_bbox(at.tonumpy(img[0]),\n",
    "#          at.tonumpy(_bboxes[0]),\n",
    "#          at.tonumpy(_labels[0]).reshape(-1),\n",
    "#          at.tonumpy(_scores[0]).reshape(-1))\n",
    "# it failed to find the dog, but if you set threshold from 0.7 to 0.6, you'll find it\n",
    "\n",
    "# Debug: Print all detected labels and their scores\n",
    "# print(\"Detected labels and scores:\")\n",
    "# for label, score in zip(labels, scores):\n",
    "#     print(f\"Label: {label}, Score: {score}\")\n",
    "\n",
    "# Convert predictions to numpy\n",
    "bboxes = at.tonumpy(_bboxes[0])\n",
    "labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "\n",
    "# # Filter predictions to show only \"person\" class\n",
    "person_class_id = 14\n",
    "person_indices = labels == person_class_id\n",
    "person_bboxes = bboxes[person_indices]\n",
    "person_labels = labels[person_indices]\n",
    "person_scores = scores[person_indices]\n",
    "\n",
    "# # Visualize only \"person\" class predictions\n",
    "vis_bbox(at.tonumpy(img[0]),\n",
    "         person_bboxes,\n",
    "         person_labels,\n",
    "         person_scores)\n",
    "\n",
    "# Save the image\n",
    "#save_path = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/cropped_imgs/orl_without_bboxes.jpg'  # Replace with your desired path\n",
    "#normalized_tensor = (img - img.min()) / (img.max() - img.min())\n",
    "#torchvision.utils.save_image(normalized_tensor, save_path, format='jpeg')\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('misc/s15538.jpg')\n",
    "\n",
    "# Define the \"person\" bounding boxes\n",
    "bounding_boxes = person_bboxes\n",
    "\n",
    "# Convert bounding box coordinates to integers\n",
    "bounding_boxes = [[int(coord) for coord in box] for box in bounding_boxes]\n",
    "\n",
    "# Draw the bounding boxes on the image\n",
    "for i, box in enumerate(bounding_boxes):\n",
    "    x1, y1, x2, y2 = box\n",
    "    #cv2.rectangle(image, (y1, x1), (y2, x2), (0, 255, 0), 2)  # (0, 255, 0) is the color (green), 2 is the thickness\n",
    "\n",
    "    # Crop the images within the bounding boxes\n",
    "    cropped_image = image[x1:x2, y1:y2]\n",
    "    \n",
    "    # Save the cropped images\n",
    "    cv2.imwrite(f'/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/cropped_imgs/cropped_image_{i}.jpg', cropped_image)\n",
    "\n",
    "    print(\"{}: {}, {}, {}, {}\".format(i, y1, x1, y2, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. model trained with caffe pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trainer.load('/home/cy/fasterrcnn_12222105_0.712649824453_caffe_pretrain.pth')\n",
    "opt.caffe_pretrain=True # this model was trained from caffe-pretrained model\n",
    "_bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "vis_bbox(at.tonumpy(img[0]),\n",
    "         at.tonumpy(_bboxes[0]),\n",
    "         at.tonumpy(_labels[0]).reshape(-1),\n",
    "         at.tonumpy(_scores[0]).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_train = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/Train.mat')\n",
    "\n",
    "data_train = mat_train['Train']\n",
    "\n",
    "lst_persons = []\n",
    "lst_image = []\n",
    "lst_images = []\n",
    "lst_coordinates = []\n",
    "\n",
    "for sample in data_train: \n",
    "    #print(sample[0][0][0][0]) # Persons\n",
    "    id_person = int(str(sample[0][0][0][0]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', ''))\n",
    "    lst_persons.append(id_person)\n",
    "    for sample_2 in sample[0][0][0][2][0]:\n",
    "        #print(sample_2[0]) # Images of person\n",
    "        name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "        lst_image.append(name_image)\n",
    "        #print(sample_2[1]) # Coordinates\n",
    "        number_coordinates = str(sample_2[1]).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "        number_coordinates = number_coordinates.split(\" \")\n",
    "        lst_coordinates.append(number_coordinates)\n",
    "    lst_images.append(lst_image)\n",
    "    lst_image = []\n",
    "\n",
    "#print(lst_persons)\n",
    "#print(lst_image)\n",
    "#print(lst_images)\n",
    "#print(lst_coordinates)\n",
    "#total_elements = sum(len(sublist) for sublist in lst_images)\n",
    "#print(total_elements)\n",
    "\n",
    "#i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "z = 1\n",
    "#flag_empty_coordinate = 0\n",
    "counter_number_persons_with_empty_bounding_boxes = 0\n",
    "\n",
    "for sample in lst_persons:\n",
    "    name_person = sample\n",
    "    for sample_2 in lst_images[j]:\n",
    "        image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{sample_2}')\n",
    "        name_image_cleaner = sample_2.replace('s', '')\n",
    "        if lst_coordinates[k][0] != '' and lst_coordinates[k][1] != '' and lst_coordinates[k][2] != '' and lst_coordinates[k][3] != '':\n",
    "            xmin, ymin, width, height = int(lst_coordinates[k][0]), int(lst_coordinates[k][1]), int(lst_coordinates[k][2]), int(lst_coordinates[k][3])\n",
    "            y2, x2 = ymin + height, xmin + width\n",
    "            cropped_image = image[ymin:y2, xmin:x2]\n",
    "            cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_train/{name_person}_c{z}s1_000000_{name_image_cleaner}', cropped_image)\n",
    "            z = z + 1\n",
    "        #else:\n",
    "            #print(name_person, end=',') # Persons with some empty coordinate in an image (not being considered)\n",
    "            #flag_empty_coordinate = 1\n",
    "        k = k + 1\n",
    "    if z == 1:\n",
    "        counter_number_persons_with_empty_bounding_boxes = counter_number_persons_with_empty_bounding_boxes + 1\n",
    "    j = j + 1\n",
    "    z = 1\n",
    "    #if flag_empty_coordinate == 1:\n",
    "        #directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/bounding_box_train/'\n",
    "        #for filename in os.listdir(directory):\n",
    "            #if filename.startswith(str(name_person)):\n",
    "                #file_path = os.path.join(directory, filename)\n",
    "                #os.remove(file_path)\n",
    "        #flag_empty_coordinate = 0\n",
    "    #else:\n",
    "        #i = i + 1\n",
    "    #if i == 751:\n",
    "        #break\n",
    "\n",
    "print(counter_number_persons_with_empty_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_query = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "data_query = mat_query['TestG100']\n",
    "\n",
    "lst_persons = []\n",
    "lst_persons_with_empty_coordinates = []\n",
    "lst_image = []\n",
    "lst_coordinates = []\n",
    "\n",
    "for sample in data_query[0]:\n",
    "     #print(sample[0][0][0][0][3]]) # Persons\n",
    "    id_person = int(str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', ''))\n",
    "    lst_persons.append(id_person)\n",
    "    for sample_2 in sample[0][0]:\n",
    "        #print(sample_2[0]) # Image of persons\n",
    "        name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "        lst_image.append(name_image)\n",
    "        #print(sample_2[1]) # Coordinates\n",
    "        number_coordinates = str(sample_2[1]).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "        number_coordinates = number_coordinates.split(\" \")\n",
    "        lst_coordinates.append(number_coordinates)\n",
    "\n",
    "#print(lst_persons)\n",
    "#print(lst_image)\n",
    "#print(lst_coordinates)\n",
    "\n",
    "# i = 0\n",
    "j = 0\n",
    "# k = 0\n",
    "# z = 1\n",
    "# flag_empty_coordinate = 0\n",
    "counter_number_persons_with_empty_bounding_boxes = 0\n",
    "\n",
    "for sample in lst_persons:\n",
    "    name_person = sample\n",
    "    name_image = lst_image[j]\n",
    "    image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{name_image}')\n",
    "    name_image_cleaner = name_image.replace('s', '')\n",
    "    if lst_coordinates[j][0] != '' and lst_coordinates[j][1] != '' and lst_coordinates[j][2] != '' and lst_coordinates[j][3] != '':\n",
    "        xmin, ymin, width, height = int(lst_coordinates[j][0]), int(lst_coordinates[j][1]), int(lst_coordinates[j][2]), int(lst_coordinates[j][3])\n",
    "        y2, x2 = ymin + height, xmin + width\n",
    "        cropped_image = image[ymin:y2, xmin:x2]\n",
    "        cv2.imwrite(f'datasets/cuhk_sysu/query/{name_person}_c1s1_000000_{name_image_cleaner}', cropped_image)\n",
    "    #z = z + 1\n",
    "    #else:\n",
    "        #print(name_person, end=',') # Persons with some empty coordinate in an image (not being considered)\n",
    "        #flag_empty_coordinate = 1\n",
    "    #k = k + 1\n",
    "    #if z == 1:\n",
    "    else:\n",
    "        lst_persons_with_empty_coordinates.append(name_person)\n",
    "        counter_number_persons_with_empty_bounding_boxes = counter_number_persons_with_empty_bounding_boxes + 1\n",
    "    j = j + 1\n",
    "    #z = 1\n",
    "    #if flag_empty_coordinate == 1:\n",
    "        #directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query/'\n",
    "        #for filename in os.listdir(directory):\n",
    "            #if filename.startswith(str(name_person)):\n",
    "                #file_path = os.path.join(directory, filename)\n",
    "                #os.remove(file_path)\n",
    "        #flag_empty_coordinate = 0\n",
    "    #else:\n",
    "        #i = i + 1\n",
    "    #if i == 750:\n",
    "        #break\n",
    "\n",
    "lst_persons_test = [item for item in lst_persons if item not in lst_persons_with_empty_coordinates]\n",
    "\n",
    "print(counter_number_persons_with_empty_bounding_boxes)\n",
    "print(len(lst_persons_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_test = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "data_test = mat_test['TestG100']\n",
    "\n",
    "lst_persons_with_empty_coordinates = []\n",
    "dict_person_images = {}\n",
    "dict_image_coordinates = {}\n",
    "\n",
    "for sample in data_test[0]:\n",
    "    id_person = str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    dict_person_images[id_person] = []\n",
    "    for sample_2 in sample[1][0]:\n",
    "        sample_coordinate = sample_2[1]\n",
    "        if sample_coordinate.size != 0:\n",
    "            name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "            dict_image_coordinates[name_image] = []\n",
    "            dict_person_images[id_person].append(name_image)\n",
    "            number_coordinates = str(sample_coordinate).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "            number_coordinates = number_coordinates.split(\" \")\n",
    "            dict_image_coordinates[name_image].append(number_coordinates)\n",
    "\n",
    "#print(dict_person_images)\n",
    "#print(dict_image_coordinates)\n",
    "#total_elements = sum(len(sublist) for sublist in lst_images)\n",
    "#print(total_elements)\n",
    "\n",
    "#i = 0\n",
    "#j = 0\n",
    "#k = 0\n",
    "z = 2\n",
    "#flag_empty_coordinate = 0\n",
    "counter_number_persons_with_empty_bounding_boxes = 0\n",
    "\n",
    "for sample in lst_persons_test:\n",
    "    name_person = sample\n",
    "    for key, value in dict_person_images.items():\n",
    "        if int(key) == name_person:\n",
    "            for sample_2 in dict_person_images[key]:\n",
    "                name_image = sample_2\n",
    "                image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{sample_2}')\n",
    "                name_image_cleaner = sample_2.replace('s', '')\n",
    "                for key, value in dict_image_coordinates.items():\n",
    "                    if key == name_image:\n",
    "                        if dict_image_coordinates[key][0][0] != '' and dict_image_coordinates[key][0][1] != '' and dict_image_coordinates[key][0][2] != '' and dict_image_coordinates[key][0][3] != '':\n",
    "                            xmin, ymin, width, height = int(dict_image_coordinates[key][0][0]), int(dict_image_coordinates[key][0][1]), int(dict_image_coordinates[key][0][2]), int(dict_image_coordinates[key][0][3])\n",
    "                            y2, x2 = ymin + height, xmin + width\n",
    "                            cropped_image = image[ymin:y2, xmin:x2]\n",
    "                            cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{name_person}_c{z}s1_000000_{name_image_cleaner}', cropped_image)\n",
    "                            z = z + 1\n",
    "            if z == 2:\n",
    "                counter_number_persons_with_empty_bounding_boxes = counter_number_persons_with_empty_bounding_boxes + 1\n",
    "                lst_persons_with_empty_coordinates.append(name_person)\n",
    "    z = 2\n",
    "\n",
    "directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/query/'\n",
    "for sample_3 in lst_persons_with_empty_coordinates:\n",
    "    name_person = sample_3\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(str(name_person) + '_'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)\n",
    "\n",
    "lst_persons_final = [item for item in lst_persons_test if item not in lst_persons_with_empty_coordinates]\n",
    "\n",
    "print(counter_number_persons_with_empty_bounding_boxes)\n",
    "print(len(lst_persons_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/pool.mat')\n",
    "\n",
    "pool_data = pool_mat['pool']\n",
    "\n",
    "lst_pool_images = []\n",
    "\n",
    "for sample in pool_data:\n",
    "    name_image = str(sample[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_pool_images.append(name_image)\n",
    "\n",
    "testg100_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "testg100_data = testg100_mat['TestG100']\n",
    "\n",
    "lst_testg100_images = []\n",
    "lst_testg100_persons = []\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    name_image = str(sample[0][0][0][0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    id_person = str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    #print(sample)\n",
    "    lst_testg100_images.append(name_image)\n",
    "    lst_testg100_persons.append(id_person)\n",
    "    teste = int(id_person)\n",
    "    if teste in lst_persons:\n",
    "        print(\"ok\")\n",
    "\n",
    "# lst_images = []    \n",
    "\n",
    "# lst_images = [item for item in lst_pool_images if item not in lst_testg100_images]\n",
    "\n",
    "# dict_testg100_images = {}\n",
    "# dict_testg100_coordinates = {}\n",
    "\n",
    "# for sample in testg100_data[0]:\n",
    "#     id_person = str(sample[0][0][0][3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "#     dict_testg100_images[id_person] = []\n",
    "#     for sample_2 in sample[1][0]:\n",
    "#         sample_coordinate = sample_2[1]\n",
    "#         if sample_coordinate.size != 0:\n",
    "#             name_image = str(sample_2[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "#             dict_testg100_coordinates[name_image] = []\n",
    "#             dict_testg100_images[id_person].append(name_image)\n",
    "#             number_coordinates = str(sample_coordinate).replace('[', '').replace(\"'\", '').replace(']', '').replace('  ', ' ')\n",
    "#             number_coordinates = number_coordinates.split(\" \")\n",
    "#             dict_testg100_coordinates[name_image].append(number_coordinates)\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "#common_elements = [element for element in lst_testg100_persons if element in lst_persons]\n",
    "#print(common_elements)\n",
    "\n",
    "#print(lst_pool_images)\n",
    "#print(lst_testg100_images)\n",
    "#print(lst_testg100_persons)\n",
    "#print(lst_images)\n",
    "#print(dict_testg100_images)\n",
    "#print(dict_testg100_coordinates)\n",
    "#total_elements = sum(len(sublist) for sublist in lst_images)\n",
    "#print(total_elements)\n",
    "\n",
    "# lst_persons_2 = []\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# k = 0\n",
    "# flag_empty_coordinate = 0\n",
    "\n",
    "# for sample in lst_images:\n",
    "#     name_person = sample\n",
    "#     for key, value in dict_testg100_images.items():\n",
    "#         if name_person in value:\n",
    "#             id_person = key\n",
    "#             lst_persons_2.append(int(id_person))\n",
    "\n",
    "# for key, value in dict_testg100_images.items():\n",
    "#     id_person = int(key)\n",
    "#     #if id_person in lst_persons_2:\n",
    "#         #print(id_person)\n",
    "\n",
    "# print(lst_persons[0])\n",
    "# print(lst_persons_2[0])\n",
    "\n",
    "# Using list comprehension to find common elements\n",
    "#common_elements = [element for element in lst_persons if element in lst_persons_2]\n",
    "\n",
    "#print(common_elements)\n",
    "\n",
    "#print(lst_persons_2)\n",
    "            \n",
    "    \n",
    "\n",
    "# for sample in lst_persons:\n",
    "#     name_person = sample\n",
    "#     for key, value in dict_testg100_imgs.items():\n",
    "#         if name_person in value:\n",
    "#             id_person = key\n",
    "#         image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{sample_2}')\n",
    "#         name_image_cleaner = sample_2.replace('s', '')\n",
    "#         if lst_coordinates[k][0] != '' and lst_coordinates[k][1] != '' and lst_coordinates[k][2] != '' and lst_coordinates[k][3] != '':\n",
    "#             xmin, ymin, width, height = int(lst_coordinates[k][0]), int(lst_coordinates[k][1]), int(lst_coordinates[k][2]), int(lst_coordinates[k][3])\n",
    "#             y2, x2 = ymin + height, xmin + width\n",
    "#             cropped_image = image[ymin:y2, xmin:x2]\n",
    "#             cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{name_person}_c1s1_000000_{name_image_cleaner}', cropped_image)\n",
    "#         else:\n",
    "#             #print(name_person, end=',') # Persons with some empty coordinate in an image (not being considered)\n",
    "#             flag_empty_coordinate = 1\n",
    "#         k = k + 1\n",
    "#     j = j + 1\n",
    "#     if flag_empty_coordinate == 1:\n",
    "#         directory = '/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/bounding_box_test/'\n",
    "#         for filename in os.listdir(directory):\n",
    "#             if filename.startswith(str(name_person)):\n",
    "#                 file_path = os.path.join(directory, filename)\n",
    "#                 os.remove(file_path)\n",
    "#         flag_empty_coordinate = 0\n",
    "#     else:\n",
    "#         i = i + 1\n",
    "#     if i == 750:\n",
    "#         break\n",
    "\n",
    "# for key, value in dict_testg100_imgs.items():\n",
    "#     if img_name in value:\n",
    "#         person_identity = key\n",
    "#         cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{person_identity}_c1s1_000000_0{img_name_cleaner}', cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "#print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "#print(\"Header:\", mat['__header__'])\n",
    "#print(\"Version:\", mat['__version__'])\n",
    "#print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'TestG100'\n",
    "testg100_data = mat['TestG100']\n",
    "#print(\"TestG100 Data:\", testg100_data)\n",
    "\n",
    "# Loop through each sample\n",
    "for sample in testg100_data[0]:  # Assuming test100g_data[0] to get to the actual data if it's structured with an extra dimension\n",
    "    sample_img = sample[0][0][0]  # Image\n",
    "    #for sample_2 in sample_img:\n",
    "        #sample_img_2 = sample_2\n",
    "    #sample_img_2 = sample[0][0][0][1]  # Location\n",
    "    #sample_img_3 = sample[1][0][1][1]  # Location\n",
    "    #print(str(sample_img) + str(sample_img_2) + str(sample_img_3))\n",
    "    \n",
    "    #print(str(sample_img))\n",
    "    #print(str(sample_img[3]))\n",
    "    #lst_person.append(str(sample_img[3]))\n",
    "    #i = i + 1\n",
    "\n",
    "    img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    img_name_cleaner = img_name.replace('s', '')\n",
    "\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "\n",
    "    img_coordinates = str(sample_img[1]).replace('[', '').replace(']', '')\n",
    "\n",
    "    lst_img_coordinates = img_coordinates.split()\n",
    "\n",
    "    lst_img_coordinates = [int(coordinate) for coordinate in lst_img_coordinates]\n",
    "    \n",
    "    xmin, ymin, width, height = lst_img_coordinates[0], lst_img_coordinates[1], lst_img_coordinates[2], lst_img_coordinates[3]\n",
    "    y2, x2 = ymin + height, xmin + width\n",
    "    \n",
    "    cropped_image = image[ymin:y2, xmin:x2]\n",
    "\n",
    "    cv2.imwrite(f'datasets/cuhk_sysu/query/{person_identity}_c1s1_000000_{img_name_cleaner}', cropped_image)\n",
    "\n",
    "    #print(str(sample_img[0]))\n",
    "    #print(str(sample_img[1]))\n",
    "    #print(\"{}, {}\".format(str(sample_img[0]), str(sample_img[1])))\n",
    "\n",
    "#lst_person_cleaned = [s.replace('[', '').replace(']', '').replace(\"'\", '').replace('\"', '') for s in lst_person]\n",
    "\n",
    "#unique_set = set(lst_person_cleaned)\n",
    "\n",
    "# Check for duplicates\n",
    "#if len(unique_set) != len(lst_person_cleaned):\n",
    "    #print(\"There are duplicate elements.\")\n",
    "#else:\n",
    "    #print(\"All elements are unique.\")\n",
    "\n",
    "#print(sorted(lst_person_cleaned))\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/pool.mat')\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "#print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "#print(\"Header:\", mat['__header__'])\n",
    "#print(\"Version:\", mat['__version__'])\n",
    "#print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'TestG50'\n",
    "testg100_data = mat['pool']\n",
    "#print(\"TestG100 Data:\", testg100_data)\n",
    "\n",
    "# Loop through each sample\n",
    "for sample in testg100_data:  # Assuming testg100g_data[0] to get to the actual data if it's structured with an extra dimension\n",
    "    #sample_img = sample[0][0][0]  # Image\n",
    "    sample_img = sample  # Image\n",
    "    #print(str(sample_img[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pool MAT file\n",
    "pool_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/pool.mat')\n",
    "\n",
    "pool_data = pool_mat['pool']\n",
    "\n",
    "lst_pool_imgs = []\n",
    "\n",
    "for sample in pool_data:\n",
    "    sample_img = sample[0]\n",
    "    img_name = str(sample_img).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_pool_imgs.append(img_name)\n",
    "\n",
    "# Load TestG100 MAT file\n",
    "testg100_mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/TestG100.mat')\n",
    "\n",
    "testg100_data = testg100_mat['TestG100']\n",
    "\n",
    "lst_testg100_imgs = []\n",
    "lst_testg100_persons = []\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    sample_img = sample[0][0][0]\n",
    "    sample_person = sample[0][0]\n",
    "    img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    lst_testg100_imgs.append(img_name)\n",
    "    lst_testg100_persons.append(person_identity)\n",
    "    \n",
    "\n",
    "lst_imgs = [item for item in lst_pool_imgs if item not in lst_testg100_imgs]\n",
    "\n",
    "dict_testg100_imgs = {}\n",
    "\n",
    "for sample in testg100_data[0]:\n",
    "    sample_img = sample[0][0][0]\n",
    "    person_identity = str(sample_img[3]).replace('p', '').replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "    dict_testg100_imgs[person_identity] = []\n",
    "    for sample_2 in sample[1][0]:\n",
    "        sample_coordinate = sample_2[1]\n",
    "        if sample_coordinate.size != 0:\n",
    "            sample_img_2 = sample_2[0]\n",
    "            img_name = str(sample_img_2).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "            dict_testg100_imgs[person_identity].append(img_name)\n",
    "\n",
    "#dict_testg100_imgs = {key: ', '.join(value) for key, value in dict_testg100_imgs.items()}\n",
    "\n",
    "#print(len(lst_imgs))\n",
    "#print(lst_testg100_imgs[0])\n",
    "#print(lst_testg100_persons[0])\n",
    "#print(lst_imgs[0])\n",
    "#print(dict_testg100_imgs)\n",
    "#first_key = next(iter(dict_testg100_imgs))\n",
    "#first_elements = dict_testg100_imgs[first_key]\n",
    "#print(f\"First key: {first_key}\")\n",
    "#print(\"Elements:\", first_elements)\n",
    "\n",
    "#def print_duplicates(input_list):\n",
    "    #i = 0\n",
    "    #seen = set()\n",
    "    #duplicates = set()\n",
    "    #for item in input_list:\n",
    "        #if item in seen:\n",
    "            #duplicates.add(item)\n",
    "        #seen.add(item)\n",
    "    #for duplicate in duplicates:\n",
    "        #print(duplicate)\n",
    "        #i = i + 1\n",
    "    #print(i)\n",
    "\n",
    "# Example usage:\n",
    "#print_duplicates(lst_testg100_imgs)\n",
    "#print(len(lst_imgs) - 167)\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "#print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "#print(\"Header:\", mat['__header__'])\n",
    "#print(\"Version:\", mat['__version__'])\n",
    "#print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'TestG50'\n",
    "#testg100_data = mat['TestG100']\n",
    "#print(\"TestG100 Data:\", testg100_data)\n",
    "\n",
    "trainer.load('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/pretrained_weights/fasterrcnn_12211511_0.701052458187_torchvision_pretrain.pth')\n",
    "opt.caffe_pretrain=False # this model was trained from torchvision-pretrained model\n",
    "\n",
    "#directory = 'datasets/cuhk_sysu/Image/SSM/'\n",
    "#lst_imgs_path = []\n",
    "\n",
    "#for root, dirs, files in os.walk(directory):\n",
    "    #for file in files:\n",
    "        #img_path = os.path.join(root, file)\n",
    "        #lst_imgs_path.append(img_path)\n",
    "\n",
    "#lst_imgs_path = [path.split('SSM/')[1] for path in lst_imgs_path]\n",
    "\n",
    "# Loop through each sample\n",
    "#for sample in testg100_data[0]:  # Assuming testg100g_data[0] to get to the actual data if it's structured with an extra dimension\n",
    "    #sample_img = sample[0][0][0]  # Image\n",
    "for sample in lst_imgs:\n",
    "    #sample_img = sample  # Image\n",
    "    #for sample_2 in sample_img:\n",
    "        #sample_img_2 = sample_2\n",
    "    #sample_img_2 = sample[0][0][0][1]  # Location\n",
    "    #sample_img_3 = sample[1][0][1][1]  # Location\n",
    "    #print(str(sample_img) + str(sample_img_2) + str(sample_img_3))\n",
    "    \n",
    "    #print(str(sample_img))\n",
    "    #print(str(sample_img[3]))\n",
    "    #lst_person.append(str(sample_img[3]))\n",
    "    #i = i + 1\n",
    "\n",
    "    #img_name = str(sample_img[1][0][1][0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    #img_name = str(sample_img[0]).replace('[', '').replace(\"'\", '').replace(']', '')\n",
    "\n",
    "    #if img_name in lst_imgs_path:\n",
    "       #print(len(lst_imgs_path))\n",
    "        \n",
    "        #pass\n",
    "    \n",
    "    #else:\n",
    "\n",
    "        #print(\"b\")\n",
    "\n",
    "    img_name = sample\n",
    "\n",
    "    img_name_cleaner = img_name.replace('s', '')\n",
    "\n",
    "    img = read_image(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "    \n",
    "    image = cv2.imread(f'datasets/cuhk_sysu/Image/SSM/{img_name}')\n",
    "    \n",
    "    img = t.from_numpy(img)[None]\n",
    "    \n",
    "    _bboxes, _labels, _scores = trainer.faster_rcnn.predict(img,visualize=True)\n",
    "    \n",
    "    bboxes = at.tonumpy(_bboxes[0])\n",
    "    labels = at.tonumpy(_labels[0]).reshape(-1)\n",
    "    scores = at.tonumpy(_scores[0]).reshape(-1)\n",
    "        \n",
    "    person_class_id = 14\n",
    "    person_indices = labels == person_class_id\n",
    "    person_bboxes = bboxes[person_indices]\n",
    "    person_labels = labels[person_indices]\n",
    "    person_scores = scores[person_indices]\n",
    "    \n",
    "    bounding_boxes = person_bboxes\n",
    "    \n",
    "    bounding_boxes = [[int(coordinate) for coordinate in box] for box in bounding_boxes]\n",
    "    \n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cropped_image = image[x1:x2, y1:y2]\n",
    "        for key, value in dict_testg100_imgs.items():\n",
    "            if img_name in value:\n",
    "                person_identity = key\n",
    "                cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/{person_identity}_c1s1_000000_0{img_name_cleaner}', cropped_image)\n",
    "            #else:\n",
    "                #cv2.imwrite(f'datasets/cuhk_sysu/bounding_box_test/00000_c1s1_000000_0{img_name_cleaner}', cropped_image)\n",
    "                #break\n",
    "\n",
    "    #print(str(sample_img[1][0][1][0]))\n",
    "    #print(str(sample_img[1][0][1][1]))\n",
    "    #print(str(sample_img[1]))\n",
    "    #print(\"{}, {}\".format(str(sample_img[0]), str(sample_img[1])))\n",
    "\n",
    "#lst_person_cleaned = [s.replace('[', '').replace(']', '').replace(\"'\", '').replace('\"', '') for s in lst_person]\n",
    "\n",
    "#unique_set = set(lst_person_cleaned)\n",
    "\n",
    "# Check for duplicates\n",
    "#if len(unique_set) != len(lst_person_cleaned):\n",
    "    #print(\"There are duplicate elements.\")\n",
    "#else:\n",
    "    #print(\"All elements are unique.\")\n",
    "\n",
    "#print(sorted(lst_person_cleaned))\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/train_test/0001_c1s1_001051_00_good.mat')\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "#print(\"Header:\", mat['__header__'])\n",
    "#print(\"Version:\", mat['__version__'])\n",
    "#print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'TestG50'\n",
    "test_data = mat['good_index']\n",
    "print(\"Test Data:\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/Images.mat')\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "#print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "print(\"Header:\", mat['__header__'])\n",
    "print(\"Version:\", mat['__version__'])\n",
    "print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'Person'\n",
    "image_data = mat['Img']\n",
    "#print(\"Image Data:\", image_data)\n",
    "\n",
    "# Since 'Image' is likely a structured array in MATLAB, it's loaded as a numpy structured array in Python.\n",
    "# Let's iterate through each person and print their data in a more structured way.\n",
    "\n",
    "# Loop through each image entry in the array\n",
    "for image in image_data[0]:  # Assuming image_data[0] to get to the actual data if it's structured with an extra dimension\n",
    "    image_name = image[0][0]  # Image name\n",
    "    detection_count = image[1][0]  # Number of detections\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print(f\"Detections: {detection_count}\")\n",
    "    print(\"Details:\")\n",
    "    \n",
    "    # Each 'detail' contains 'idlocate' and 'ishard'\n",
    "    for detail in image[2]:  \n",
    "        # Coordinates are in 'idlocate' and the status (e.g., is hard) in 'ishard'\n",
    "        coordinates = detail['idlocate'][0]\n",
    "        is_hard = detail['ishard'][0][0]\n",
    "        print(f\"  Coordinates: {coordinates}\")\n",
    "        print(f\"  Is Hard: {is_hard}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/Person.mat')\n",
    "\n",
    "# Print header and version information\n",
    "print(\"Header:\", mat['__header__'])\n",
    "print(\"Version:\", mat['__version__'])\n",
    "print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'Person'\n",
    "#person_data = mat['Person']\n",
    "#print(\"Person Data:\", person_data)\n",
    "\n",
    "# Since 'Person' is likely a structured array in MATLAB, it's loaded as a numpy structured array in Python.\n",
    "# Let's iterate through each person and print their data in a more structured way.\n",
    "\n",
    "# Assuming person_data is a structured array with fields that can be indexed by name\n",
    "for person in person_data[0]:  # person_data[0] because it is likely a 2D array with one actual dimension\n",
    "    print(\"Person ID:\", person[0][0])  # Person ID\n",
    "    print(\"Appearing Time:\", person[1][0])  # Some count, assuming it's in the second position\n",
    "    print(\"Scene Location:\")\n",
    "    for detail in person[2]:  # Assuming details are in the third position and it's an array of structured arrays\n",
    "        print(f\"  Image Name: {detail['imname'][0]}\")\n",
    "        print(f\"  Location: {detail['idlocate'][0]}\")\n",
    "        print(f\"  Unknown: {detail['ishard'][0][0]}\")\n",
    "        print(\"-\" * 30)\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/pool.mat')\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "print(\"Header:\", mat['__header__'])\n",
    "print(\"Version:\", mat['__version__'])\n",
    "print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'pool'\n",
    "pool_data = mat['pool']\n",
    "print(\"Pool Data:\", pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAT file\n",
    "mat = scipy.io.loadmat('/home/eduardoandrade/Phd/experiments/models/od/simple-faster-rcnn-pytorch/datasets/cuhk_sysu/annotation/test/subset/Occlusion.mat')\n",
    "\n",
    "# # Display all variable names contained in the file\n",
    "print(mat.keys())\n",
    "\n",
    "# Print header and version information\n",
    "print(\"Header:\", mat['__header__'])\n",
    "print(\"Version:\", mat['__version__'])\n",
    "print(\"Globals:\", mat['__globals__'])\n",
    "\n",
    "# Access and print data in 'pool'\n",
    "pool_data = mat['Occlusion1']\n",
    "print(\"Test_Size Data:\", pool_data)\n",
    "\n",
    "# Access 'Test_Size' data\n",
    "#test_size_data = mat['Test_Size']\n",
    "\n",
    "# Print only the first few elements of 'Test_Size' to avoid too much output\n",
    "#print(\"Test_Size Data (first few entries):\", test_size_data[:5])\n",
    "\n",
    "# Additional summary information, like the shape and datatype\n",
    "#print(\"Total number of entries in Test_Size:\", test_size_data.size)\n",
    "#print(\"Data type of Test_Size entries:\", test_size_data.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
